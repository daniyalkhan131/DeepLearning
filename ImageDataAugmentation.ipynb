{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7DM1E0WOayHm"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import image #it is like cv2 for working on images in keras\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img=image.load_img(\"/content/pexels-peng-louis-1643457.jpg\",target_size=(256,256))"
      ],
      "metadata": {
        "id": "fdphcZFsbYbI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "5fb7f949-6aea-4750-dd35-faa12c71cfa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6527491cbd0c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/pexels-peng-louis-1643457.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/pexels-peng-louis-1643457.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img #it is not numpy array it is in pil format\n",
        "#type(img)"
      ],
      "metadata": {
        "id": "Ia6G2_KgbheW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen= ImageDataGenerator(\n",
        "    rotation_range=30, #it is the angle of rotation\n",
        "    shear_range=0.2,  #image distort in this\n",
        "    zoom_range=0.2, #zoom in out both\n",
        "    horizontal_flip=True,\n",
        "    #vertical_flip=True, as cat cannot be vertical\n",
        "    width_shift_range=0.2,  #moving image side a little\n",
        "    height_shift_range=0.2  ##moving image above a little\n",
        "    #fill_mode='nearest' means that when image shifted then empty pixel populated by nearby pixels, it is default\n",
        "                                                      #constant(blax pixels),flip(mirroring done on those) is also there\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "vHAlRljXboEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img =image.img_to_array(img)#convert to numpy array"
      ],
      "metadata": {
        "id": "F5V6H3jkdKW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(img),img.shape"
      ],
      "metadata": {
        "id": "1saG4wopeE8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we have to give images in batches for augmentation\n",
        "input_batch=img.reshape(1,256,256,3) #forth dimension tell batchsize"
      ],
      "metadata": {
        "id": "oEfHYejaeGMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "for output in datagen.flow(input_batch,batch_size=1,save_to_dir='/content/aug'): #we use flow when we want to process one image\n",
        "                                    #that is present in numpy fomat directly and when we want to process image from\n",
        "                                    #directory then use diff. method of ImageDataGenerator\n",
        "  i=i+1\n",
        "  if i==10:\n",
        "    break"
      ],
      "metadata": {
        "id": "-swwccitepvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#applying data augmentation to cat dog classifier and seeing the difference before and after"
      ],
      "metadata": {
        "id": "pXGlwQA9ftOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "I4raqejJKTPa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d whenamancodes/cat-and-dog-finder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl8Kotj-Jx_P",
        "outputId": "84f69b72-8aa3-4912-ef66-b828e9881098"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading cat-and-dog-finder.zip to /content\n",
            " 98% 214M/218M [00:01<00:00, 140MB/s]\n",
            "100% 218M/218M [00:02<00:00, 114MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for unzipping\n",
        "\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/cat-and-dog-finder.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "acbQ8FOtKhB2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "tx2bbGcBNOpT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mydir = r'/content/training_set/training_set'"
      ],
      "metadata": {
        "id": "dcOAQaRfKnVt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories=['cats','dogs']"
      ],
      "metadata": {
        "id": "9PkaZQ5xLGyl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=[]\n",
        "for i in categories:\n",
        "  folder_path=os.path.join(mydir,i)\n",
        "\n",
        "  if i=='cats':\n",
        "    label=0\n",
        "  else:\n",
        "    label=1\n",
        "\n",
        "  for j in os.listdir(folder_path):\n",
        "\n",
        "    img_path=os.path.join(folder_path,j)\n",
        "    img=cv2.imread(img_path)\n",
        "    #img=cv2.resize(img,(150,150))\n",
        "    try:\n",
        "      img = cv2.resize(img, (150, 150))\n",
        "    except:\n",
        "      break\n",
        "    data.append([img,label])"
      ],
      "metadata": {
        "id": "ptGqydZLLJwC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_P0C6qmNT32",
        "outputId": "6a5b2b7a-483c-458f-a9fc-c668037a3088"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(data)"
      ],
      "metadata": {
        "id": "9SVPogVqNXre"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=[]\n",
        "y=[]\n",
        "for i in data:\n",
        "  X.append(i[0])\n",
        "  y.append(i[1])"
      ],
      "metadata": {
        "id": "q5XbLxJ2NfGX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.array(X)\n",
        "y=np.array(y)"
      ],
      "metadata": {
        "id": "FUaJUujWP_IC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape,y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WarSfrgJQClP",
        "outputId": "6c5dbd2b-3b0f-4d06-c737-d22fbff2d8cd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3095, 150, 150, 3), (3095,))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=X/255"
      ],
      "metadata": {
        "id": "HDAZDblAQFLY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Activation,Dropout,BatchNormalization"
      ],
      "metadata": {
        "id": "-kNOcsT-QJkb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(150,150,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "oq7e7_GAQWSd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "2V0o6J3KQqI2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X,y,epochs=5,validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S9uANAfQ2BE",
        "outputId": "96a7eabd-107d-493d-b9e7-366d2b93862b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "88/88 [==============================] - 17s 39ms/step - loss: 1.7079 - accuracy: 0.5641 - val_loss: 4.2246 - val_accuracy: 0.4419\n",
            "Epoch 2/5\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 0.7422 - accuracy: 0.6212 - val_loss: 1.4882 - val_accuracy: 0.4484\n",
            "Epoch 3/5\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 0.6366 - accuracy: 0.6894 - val_loss: 1.0318 - val_accuracy: 0.4548\n",
            "Epoch 4/5\n",
            "88/88 [==============================] - 3s 32ms/step - loss: 0.5526 - accuracy: 0.7318 - val_loss: 1.7919 - val_accuracy: 0.4839\n",
            "Epoch 5/5\n",
            "88/88 [==============================] - 3s 31ms/step - loss: 0.4976 - accuracy: 0.7655 - val_loss: 1.0301 - val_accuracy: 0.5742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history['accuracy'][4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SJWIuQDShKh",
        "outputId": "dc9c0b01-d0e2-4544-a76d-c06aa90c9394"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7655296325683594"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "ttDcjKV7Su6x"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=16\n",
        "\n",
        "#augmentation config for training\n",
        "train_datagen=ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "#augmentation config for testing\n",
        "#we do augmentatn in training data not manipulating testing data\n",
        "\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "IFlwloKRUlw6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for reading images from directory and indefinitely generate\n",
        "#batches of augmented image data\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory(\n",
        "    '/content/training_set/training_set',\n",
        "    target_size=(150,150),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "#for validation set\n",
        "\n",
        "validation_generator=test_datagen.flow_from_directory(\n",
        "    '/content/test_set/test_set',\n",
        "    target_size=(150,150),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx8rfuulVcNl",
        "outputId": "dca97edf-d869-49ed-fe94-fdece8186dfa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8005 images belonging to 2 classes.\n",
            "Found 2023 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now creating same model\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(150,150,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "xLM-UQezW0To"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "5FlE3AnvXwjL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#when we do augmentation then use fit_generator instead of fit\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=8005 //batch_size,\n",
        "    epochs=5,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=2023 //batch_size)\n",
        "#we dont use original data instead use generator that contain all aug. images also"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cuhyTPSXztG",
        "outputId": "cb0edce3-ab93-43fb-ad82-5822f031618e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-92570776e890>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500/500 [==============================] - 62s 119ms/step - loss: 1.3153 - accuracy: 0.5588 - val_loss: 0.8210 - val_accuracy: 0.5749\n",
            "Epoch 2/5\n",
            "500/500 [==============================] - 57s 115ms/step - loss: 0.6554 - accuracy: 0.6483 - val_loss: 0.6116 - val_accuracy: 0.6711\n",
            "Epoch 3/5\n",
            "500/500 [==============================] - 58s 117ms/step - loss: 0.5758 - accuracy: 0.7219 - val_loss: 0.5032 - val_accuracy: 0.7574\n",
            "Epoch 4/5\n",
            "500/500 [==============================] - 58s 116ms/step - loss: 0.5422 - accuracy: 0.7557 - val_loss: 0.5738 - val_accuracy: 0.7366\n",
            "Epoch 5/5\n",
            "500/500 [==============================] - 57s 114ms/step - loss: 0.5044 - accuracy: 0.7747 - val_loss: 0.5846 - val_accuracy: 0.7059\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e31abff11e0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NdkooLEfYspA"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ndk_msE4XwI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}